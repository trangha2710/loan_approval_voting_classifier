{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32f966ae",
   "metadata": {},
   "source": [
    "# Loan Approval Classification - Technical Report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5eefa4",
   "metadata": {},
   "source": [
    "\n",
    "## Objective\n",
    "\n",
    "The goal of this project is to predict **loan approval status** (`loan_status`) using a classification pipeline that handles:\n",
    "- Data preprocessing (log transforms, scaling, encoding),\n",
    "- Class imbalance (undersampling),\n",
    "- Ensemble learning (Voting Classifier),\n",
    "- Probability calibration,\n",
    "- Threshold tuning for optimal F1-score.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76892488",
   "metadata": {},
   "source": [
    "\n",
    "## Dataset\n",
    "\n",
    "The dataset consists of records containing applicant information and loan details. The target variable is:\n",
    "- `loan_status`: Binary classification (1 = approved, 0 = rejected)\n",
    "\n",
    "### Features used:\n",
    "- **Numerical:** `person_age`, `person_emp_exp`, `cb_person_cred_hist_length`, `credit_score`\n",
    "- **Log-transformed:** `person_income`, `loan_amnt`\n",
    "- **Categorical:** All object-type columns (e.g., `loan_intent`, `loan_grade`, etc.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101ce198",
   "metadata": {},
   "source": [
    "\n",
    "## Modeling Pipeline\n",
    "\n",
    "1. **Preprocessing**\n",
    "   - `person_income` and `loan_amnt` were log-transformed and scaled.\n",
    "   - Other numerical features were standardized.\n",
    "   - Categorical features were one-hot encoded using `OneHotEncoder`.\n",
    "\n",
    "2. **Imbalance Handling**\n",
    "   - Used `RandomUnderSampler` to balance the majority and minority classes.\n",
    "\n",
    "3. **Modeling**\n",
    "   - Employed a **VotingClassifier** (soft voting) combining:\n",
    "     - `DecisionTreeClassifier`\n",
    "     - `LogisticRegression`\n",
    "     - `RandomForestClassifier`\n",
    "   - All models use `class_weight='balanced'`.\n",
    "\n",
    "4. **Calibration**\n",
    "   - Applied **Isotonic Calibration** via `CalibratedClassifierCV` to improve probability estimates.\n",
    "\n",
    "5. **Threshold Tuning**\n",
    "   - Evaluated different probability thresholds to optimize **F1-score** using `precision_recall_curve`.\n",
    "   - Selected the best threshold based on maximum F1.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a81e20",
   "metadata": {},
   "source": [
    "\n",
    "## Experiment Tracking with MLflow\n",
    "\n",
    "All model training steps and evaluation metrics were tracked using MLflow, including:\n",
    "\n",
    "- Model parameters (e.g., max depth, regularization strength, class weights)\n",
    "- Preprocessing steps (e.g., log-transformed features, encoding type)\n",
    "- Performance metrics (Accuracy, Precision, Recall, F1, AUC, Brier Score)\n",
    "- Calibrated model and best-found threshold\n",
    "- Logged the trained pipeline as a reproducible MLflow model artifact\n",
    "\n",
    "This allows for:\n",
    "- Reproducibility of experiments\n",
    "- Easy comparison of different model runs\n",
    "- Deployment-ready model tracking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2616c8",
   "metadata": {},
   "source": [
    "\n",
    "## Evaluation\n",
    "\n",
    "Two evaluation settings were compared:\n",
    "\n",
    "### Threshold = 0.5 (Default)\n",
    "\n",
    "| Class | Precision | Recall | F1-score |\n",
    "|-------|-----------|--------|----------|\n",
    "| 0     | 0.97      | 0.81   | 0.88     |\n",
    "| 1     | 0.58      | 0.92   | 0.71     |\n",
    "\n",
    "- **Accuracy:** 0.83  \n",
    "- **Macro Avg F1:** 0.80  \n",
    "- **Weighted Avg F1:** 0.84  \n",
    "\n",
    "=> Very high **recall** on class `1`, but many false positives (lower precision).\n",
    "\n",
    "---\n",
    "\n",
    "### Threshold = Best F1 (≈ 0.57)\n",
    "\n",
    "| Class | Precision | Recall | F1-score |\n",
    "|-------|-----------|--------|----------|\n",
    "| 0     | 0.92      | 0.92   | 0.92     |\n",
    "| 1     | 0.74      | 0.74   | 0.74     |\n",
    "\n",
    "- **Accuracy:** 0.88  \n",
    "- **Macro Avg F1:** 0.83  \n",
    "- **Weighted Avg F1:** 0.88  \n",
    "\n",
    "=> Balanced performance between precision and recall across both classes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f0344e",
   "metadata": {},
   "source": [
    "\n",
    "##  Additional Metrics\n",
    "\n",
    "- **AUC-ROC:** `~0.94`\n",
    "- **Average Precision (PR AUC):** `~0.88`\n",
    "- **Brier Score:** `0.1004`\n",
    "  - Interpretation: Low score → good probability calibration.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b89d15",
   "metadata": {},
   "source": [
    "\n",
    "##  Conclusions\n",
    "\n",
    "- Threshold tuning significantly improved model balance and accuracy.\n",
    "- Isotonic calibration further refined predicted probabilities.\n",
    "- The model generalizes well with solid performance on both recall and precision.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683adaf9",
   "metadata": {},
   "source": [
    "\n",
    "## Future Improvement\n",
    "\n",
    "- Deploy the model using FastAPI + Kafka for streaming predictions (cloud-native)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
